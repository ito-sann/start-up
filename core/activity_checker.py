"""
ç°¡æ˜“ç‰ˆ æ´»å‹•çŠ¶æ³åˆ¤å®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰
Playwrightã§ã‚µã‚¤ãƒˆã‚’å·¡å›ã—ã€æ­£è¦è¡¨ç¾ã§æ—¥ä»˜ã‚’æŠ½å‡ºã—ã¦2ãƒ¶æœˆãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ã™ã‚‹ã€‚
"""

import re
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from urllib.parse import urljoin
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Playwrightï¼ˆéåŒæœŸï¼‰
try:
    from playwright.async_api import async_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš  PlaywrightãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install playwright && playwright install ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")


# æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ—¥æœ¬èªã‚µã‚¤ãƒˆå‘ã‘ï¼‰
DATE_PATTERNS = [
    # 2026å¹´2æœˆ4æ—¥, 2026å¹´02æœˆ04æ—¥
    r'(\d{4})å¹´\s*(\d{1,2})æœˆ\s*(\d{1,2})æ—¥',
    # 2026/2/4, 2026/02/04
    r'(\d{4})/(\d{1,2})/(\d{1,2})',
    # 2026-02-04
    r'(\d{4})-(\d{2})-(\d{2})',
    # 2026.02.04
    r'(\d{4})\.(\d{2})\.(\d{2})',
    # R8.2.4 (ä»¤å’Œ8å¹´)
    r'R(\d{1,2})\.(\d{1,2})\.(\d{1,2})',
    # ä»¤å’Œ8å¹´2æœˆ4æ—¥
    r'ä»¤å’Œ(\d{1,2})å¹´\s*(\d{1,2})æœˆ\s*(\d{1,2})æ—¥',
]

# ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã‚’ç¤ºã™ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
NEWS_KEYWORDS = ['news', 'topic', 'event', 'seminar', 'ãŠçŸ¥ã‚‰ã›', 'ãƒ‹ãƒ¥ãƒ¼ã‚¹', 'ã‚¤ãƒ™ãƒ³ãƒˆ', 'æ–°ç€', 'æ´»å‹•å ±å‘Š']


def parse_date(match: tuple, pattern_index: int) -> Optional[datetime]:
    """ãƒãƒƒãƒã—ãŸæ—¥ä»˜ã‚’datetimeã«å¤‰æ›"""
    try:
        if pattern_index in [4, 5]:  # ä»¤å’Œãƒ‘ã‚¿ãƒ¼ãƒ³
            year = 2018 + int(match[0])  # ä»¤å’Œ1å¹´ = 2019å¹´
        else:
            year = int(match[0])
        month = int(match[1])
        day = int(match[2])
        
        if 1 <= month <= 12 and 1 <= day <= 31 and 2020 <= year <= 2030:
            return datetime(year, month, day)
    except:
        pass
    return None


def extract_dates_from_text(text: str) -> List[datetime]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¨ã¦ã®æ—¥ä»˜ã‚’æŠ½å‡º"""
    dates = []
    
    for i, pattern in enumerate(DATE_PATTERNS):
        matches = re.findall(pattern, text)
        for match in matches:
            parsed = parse_date(match, i)
            if parsed:
                dates.append(parsed)
    
    return dates


class SimpleActivityChecker:
    """APIã‚­ãƒ¼ä¸è¦ã®ç°¡æ˜“ç‰ˆæ´»å‹•åˆ¤å®šã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, threshold_days: int = 60):
        self.threshold_days = threshold_days
        self.threshold_date = datetime.now() - timedelta(days=threshold_days)
    
    async def get_page_content(self, url: str) -> Optional[str]:
        """ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—"""
        if not PLAYWRIGHT_AVAILABLE:
            return None
            
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            try:
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                )
                page = await context.new_page()
                
                await page.goto(url, timeout=30000, wait_until='domcontentloaded')
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                links = await page.evaluate("""
                    Array.from(document.querySelectorAll('a')).map(a => ({
                        text: a.innerText.toLowerCase(),
                        href: a.href
                    }))
                """)
                
                news_url = None
                for link in links:
                    for kw in NEWS_KEYWORDS:
                        if kw in link['text'] or kw in link['href'].lower():
                            news_url = link['href']
                            break
                    if news_url:
                        break
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ãŒã‚ã‚Œã°ç§»å‹•
                if news_url and news_url != url:
                    try:
                        await page.goto(news_url, timeout=30000, wait_until='domcontentloaded')
                    except:
                        pass
                
                # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
                text = await page.evaluate("document.body.innerText")
                return text
                
            except Exception as e:
                print(f"  âœ— ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
                return None
            finally:
                await browser.close()
    
    async def check_facility(self, url: str, facility_name: str = "") -> Dict[str, Any]:
        """æ–½è¨­ã®æ´»å‹•çŠ¶æ³ã‚’åˆ¤å®š"""
        print(f"  ãƒã‚§ãƒƒã‚¯ä¸­: {facility_name or url}")
        
        content = await self.get_page_content(url)
        
        if not content:
            return {
                "facility_name": facility_name,
                "url": url,
                "status": "unknown",
                "reason": "ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                "latest_date": None
            }
        
        # æ—¥ä»˜æŠ½å‡º
        dates = extract_dates_from_text(content)
        
        if not dates:
            return {
                "facility_name": facility_name,
                "url": url,
                "status": "unknown",
                "reason": "æ—¥ä»˜æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                "latest_date": None
            }
        
        # æœ€æ–°æ—¥ä»˜ã‚’å–å¾—
        latest_date = max(dates)
        is_active = latest_date >= self.threshold_date
        
        return {
            "facility_name": facility_name,
            "url": url,
            "status": "active" if is_active else "dormant",
            "reason": f"æœ€æ–°æ›´æ–°: {latest_date.strftime('%Y-%m-%d')}",
            "latest_date": latest_date.strftime('%Y-%m-%d'),
            "is_active": is_active
        }
    
    async def check_all_facilities(self, facilities: List[Dict]) -> List[Dict]:
        """å…¨æ–½è¨­ã‚’ãƒã‚§ãƒƒã‚¯"""
        results = []
        
        for facility in facilities:
            url = facility.get('website')
            name = facility.get('name', '')
            
            if not url:
                continue
                
            result = await self.check_facility(url, name)
            result['facility_id'] = facility.get('id')
            results.append(result)
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆ1ç§’å¾…æ©Ÿï¼‰
            await asyncio.sleep(1)
        
        return results


async def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    checker = SimpleActivityChecker()
    
    # ãƒ†ã‚¹ãƒˆç”¨æ–½è¨­
    test_facilities = [
        {"id": "test1", "name": "Tokyo Innovation Base", "website": "https://tib.metro.tokyo.lg.jp/"},
        {"id": "test2", "name": "Venture Cafe Tokyo", "website": "https://venturecafetokyo.org/"},
    ]
    
    print("\n=== ç°¡æ˜“ç‰ˆ æ´»å‹•åˆ¤å®šãƒ†ã‚¹ãƒˆ ===\n")
    results = await checker.check_all_facilities(test_facilities)
    
    print("\n=== çµæœ ===")
    for r in results:
        status_emoji = "âœ…" if r.get('is_active') else "ğŸ’¤" if r['status'] == 'dormant' else "â“"
        print(f"{status_emoji} {r['facility_name']}: {r['status']} ({r['reason']})")


if __name__ == "__main__":
    asyncio.run(main())
